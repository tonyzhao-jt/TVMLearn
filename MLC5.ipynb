{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MLC5",
      "provenance": [],
      "authorship_tag": "ABX9TyNaadLkx+qmvnpNHLkTUDou",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SpringWave1/TVMLearn/blob/main/MLC5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 -m  pip install mlc-ai-nightly -f https://mlc.ai/wheels\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wyZLga3qosaT",
        "outputId": "59c3f35c-b7e7-44a7-ffe5-3f90b8316ef2"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Looking in links: https://mlc.ai/wheels\n",
            "Collecting mlc-ai-nightly\n",
            "  Downloading https://github.com/mlc-ai/utils/releases/download/v0.9.dev0/mlc_ai_nightly-0.9.dev1955%2Bg495ac6010-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (44.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 44.2 MB 1.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (from mlc-ai-nightly) (5.4.8)\n",
            "Collecting synr==0.6.0\n",
            "  Downloading synr-0.6.0-py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from mlc-ai-nightly) (1.7.3)\n",
            "Requirement already satisfied: tornado in /usr/local/lib/python3.7/dist-packages (from mlc-ai-nightly) (5.1.1)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.7/dist-packages (from mlc-ai-nightly) (21.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from mlc-ai-nightly) (1.21.6)\n",
            "Requirement already satisfied: Pygments in /usr/local/lib/python3.7/dist-packages (from mlc-ai-nightly) (2.6.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from mlc-ai-nightly) (4.4.2)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.7/dist-packages (from mlc-ai-nightly) (1.3.0)\n",
            "Installing collected packages: synr, mlc-ai-nightly\n",
            "Successfully installed mlc-ai-nightly-0.9.dev1955+g495ac6010 synr-0.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Z2uVsFhnoK3x"
      },
      "outputs": [],
      "source": [
        "# This is needed for deferring annotation parsing in TVMScript\n",
        "from __future__ import annotations\n",
        "import numpy as np\n",
        "import tvm\n",
        "from tvm import relax\n",
        "from tvm.ir.module import IRModule\n",
        "from tvm.script import relax as R\n",
        "from tvm.script import tir as T"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import fx\n",
        "from torch.nn import functional as F"
      ],
      "metadata": {
        "id": "snDFRc7KoPzd"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tvm import te"
      ],
      "metadata": {
        "id": "rd8jFqj-ocOS"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MyModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MyModel, self).__init__()\n",
        "        self.weight = nn.Parameter(torch.randn(128, 128))\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.matmul(x, self.weight)\n",
        "        x = torch.relu(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "Seq16mBarx9q"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = MyModel()\n",
        "fx_module = fx.symbolic_trace(model)\n",
        "type(fx_module)"
      ],
      "metadata": {
        "id": "7MG2syJiry0H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fx_module.graph.print_tabular()"
      ],
      "metadata": {
        "id": "Iywpmb8Ar6Hu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "torch graph -> relax graph"
      ],
      "metadata": {
        "id": "fwWp0CI6t8gN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def map_param(param: nn.Parameter):\n",
        "    ndim = len(param.data.shape)\n",
        "    return relax.const(\n",
        "        param.data.cpu().numpy(), relax.DynTensorType(ndim, \"float32\")\n",
        "    )\n",
        "\n",
        "def fetch_attr(fx_mod, target: str):\n",
        "    \"\"\"Helper function to fetch an attr\"\"\"\n",
        "    target_atoms = target.split('.')\n",
        "    attr_itr = fx_mod\n",
        "    for i, atom in enumerate(target_atoms):\n",
        "        if not hasattr(attr_itr, atom):\n",
        "            raise RuntimeError(f\"Node referenced nonexistant target {'.'.join(target_atoms[:i])}\")\n",
        "        attr_itr = getattr(attr_itr, atom)\n",
        "    return attr_itr\n",
        "\n",
        "def from_fx(fx_mod, input_shapes, call_function_map, call_module_map):\n",
        "    input_index = 0\n",
        "    node_map = {}\n",
        "    named_modules = dict(fx_mod.named_modules())\n",
        "\n",
        "    bb = relax.BlockBuilder()\n",
        "\n",
        "    fn_inputs = []\n",
        "    fn_output = None\n",
        "    with bb.function(\"main\"):\n",
        "        with bb.dataflow():\n",
        "            for node in fx_mod.graph.nodes:\n",
        "                if node.op == \"placeholder\":\n",
        "                    # create input placeholder\n",
        "                    shape = input_shapes[input_index]\n",
        "                    input_index += 1\n",
        "                    input_var = relax.Var(\n",
        "                        node.target, shape, relax.DynTensorType(len(shape), \"float32\")\n",
        "                    )\n",
        "                    fn_inputs.append(input_var)\n",
        "                    node_map[node] = input_var\n",
        "                elif node.op == \"get_attr\":\n",
        "                    node_map[node] = map_param(fetch_attr(fx_mod, node.target))\n",
        "                elif node.op == \"call_function\":\n",
        "                    node_map[node] = call_function_map[node.target](bb, node_map, node)\n",
        "                elif node.op == \"call_module\":\n",
        "                    named_module = named_modules[node.target]\n",
        "                    node_map[node] = call_module_map[type(named_module)](bb, node_map, node, named_module)\n",
        "                elif node.op == \"output\":\n",
        "                    output = node_map[node.args[0]]\n",
        "                    assert fn_output is None\n",
        "                    fn_output = bb.emit_output(output)\n",
        "        # output and finalize the function\n",
        "        bb.emit_func_output(output, fn_inputs)\n",
        "    return bb.get()"
      ],
      "metadata": {
        "id": "Un9m1yBHtTYS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def map_matmul(bb, node_map, node: fx.Node):\n",
        "    A = node_map[node.args[0]]\n",
        "    B = node_map[node.args[1]]\n",
        "    return bb.emit_te(te_matmul, A, B)\n",
        "\n",
        "def map_relu(bb, node_map, node: fx.Node):\n",
        "    A = node_map[node.args[0]]\n",
        "    return bb.emit_te(te_relu, A)\n",
        "\n",
        "MyModule = from_fx(\n",
        "    fx_module,\n",
        "    input_shapes = [(1, 128)],\n",
        "    call_function_map = {\n",
        "      torch.matmul: map_matmul,\n",
        "      torch.relu: map_relu,\n",
        "    },\n",
        "    call_module_map={},\n",
        ")\n",
        "\n",
        "MyModule.show()"
      ],
      "metadata": {
        "id": "Ww0YegzDuZNE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}